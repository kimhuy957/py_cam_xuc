# from django.shortcuts import render, redirect
# from django.http import HttpResponse
# import pickle
# import re
# from nltk.corpus import stopwords
# from nltk.tokenize import word_tokenize
# import nltk
# import os
# # import pickle
# # T·∫£i stopwords v√† c·∫•u h√¨nh NLTK
# nltk.download('stopwords', quiet=True)
# nltk.download('punkt', quiet=True)
# stop_words = set(stopwords.words('english'))
#
# # H√†m ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
# def preprocess_text(text):
#     text = re.sub(r'[^a-zA-Z\s]', '', text.lower())  # Lo·∫°i b·ªè k√Ω t·ª± kh√¥ng ph·∫£i ch·ªØ c√°i
#     words = word_tokenize(text)  # T√°ch t·ª´
#     words = [word for word in words if word not in stop_words]  # Lo·∫°i b·ªè stopwords
#     return ' '.join(words)
#
# # ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ƒë·∫øn t·ªáp
# BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # Th∆∞ m·ª•c hi·ªán t·∫°i
# MODEL_PATH = os.path.join(BASE_DIR, 'code_hkmay', 'sentiment_model.pkl')
# VECTORIZER_PATH = os.path.join(BASE_DIR, 'code_hkmay', 'vectorizer.pkl')
#
# # Ki·ªÉm tra v√† t·∫£i m√¥ h√¨nh, vectorizer
# if os.path.exists(MODEL_PATH) and os.path.exists(VECTORIZER_PATH):
#     with open(MODEL_PATH, 'rb') as model_file:
#         model = pickle.load(model_file)
#     with open(VECTORIZER_PATH, 'rb') as vectorizer_file:
#         tfidf = pickle.load(vectorizer_file)
# else:
#     raise FileNotFoundError("Kh√¥ng th·ªÉ t√¨m th·∫•y c√°c file c·∫ßn thi·∫øt (model/vectorizer).")
#
# # View d·ª± ƒëo√°n c·∫£m x√∫c
# def predict_sentiment(request):
#     result = None
#     NoiDung = None
#     if request.method == 'POST':
#         user_input = request.POST.get('text_camxuc')  # L·∫•y n·ªôi dung ng∆∞·ªùi d√πng nh·∫≠p
#         NoiDung = user_input
#         processed_text = preprocess_text(user_input)  # Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
#         text_vector = tfidf.transform([processed_text])  # Chuy·ªÉn vƒÉn b·∫£n th√†nh vector
#         result = model.predict(text_vector)[0]  # D·ª± ƒëo√°n c·∫£m x√∫c
#     return render(request, 'app/predict_sentiment.html', {'result': result, 'NoiDung': NoiDung})
#
# # View l∆∞u c·∫£m x√∫c "Like"
# def save_sentiment(request):
#     if request.method == "POST":
#         processed_text = request.POST.get("processed_text")
#         sentiment = request.POST.get("sentiment")
#
#         if sentiment == "like":
#             with open('training_data.csv', 'a') as f:
#                 f.write(f"{processed_text},like\n")
#             return HttpResponse("C·∫£m x√∫c ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh c√¥ng!")
#     return redirect('predict_sentiment')
#
# # View b·ªè qua c·∫£m x√∫c "No Like"
# def discard_sentiment(request):
#     return HttpResponse("C·∫£m x√∫c kh√¥ng ƒë∆∞·ª£c l∆∞u v√† ƒë√£ b·ªè qua.")


from django.shortcuts import render
from django.http import JsonResponse
import pickle
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import os
from django.shortcuts import redirect
# from django.http import JsonResponse

# T·∫£i t√†i nguy√™n NLTK c·∫ßn thi·∫øt
nltk.download('stopwords', quiet=True)
nltk.download('punkt', quiet=True)
stop_words = set(stopwords.words('english'))
# ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ƒë·∫øn t·ªáp
BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # Th∆∞ m·ª•c hi·ªán t·∫°i
MODEL_PATH = os.path.join(BASE_DIR, 'code_hkmay', 'sentiment_model.pkl')
VECTORIZER_PATH = os.path.join(BASE_DIR, 'code_hkmay', 'vectorizer.pkl')

# Ki·ªÉm tra v√† t·∫£i m√¥ h√¨nh, vectorizer
if os.path.exists(MODEL_PATH) and os.path.exists(VECTORIZER_PATH):
    with open(MODEL_PATH, 'rb') as model_file:
        model = pickle.load(model_file)
    with open(VECTORIZER_PATH, 'rb') as vectorizer_file:
        tfidf = pickle.load(vectorizer_file)
else:
    raise FileNotFoundError("Kh√¥ng th·ªÉ t√¨m th·∫•y c√°c file c·∫ßn thi·∫øt (model/vectorizer).")


# H√†m x·ª≠ l√Ω vƒÉn b·∫£n
def preprocess_text(text):
    """Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n: lo·∫°i b·ªè k√Ω t·ª± kh√¥ng c·∫ßn thi·∫øt, x√≥a stopwords."""
    text = re.sub(r'[^a-zA-Z\s]', '', text.lower())  # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng, lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát
    words = word_tokenize(text)  # T√°ch t·ª´
    words = [word for word in words if word not in stop_words]  # Lo·∫°i b·ªè stopwords
    return ' '.join(words)


# Trang ch√≠nh
def home(request):
    """Hi·ªÉn th·ªã trang ch√≠nh."""
    return render(request, 'app/home.html')


# H√†m x·ª≠ l√Ω d·ª± ƒëo√°n c·∫£m x√∫c
def test_text(request):
    """D·ª± ƒëo√°n c·∫£m x√∫c t·ª´ vƒÉn b·∫£n nh·∫≠p v√†o."""
    result = None
    NoiDung = None
    if request.method == 'POST':
        # L·∫•y d·ªØ li·ªáu t·ª´ ng∆∞·ªùi d√πng
        text_input = request.POST.get('text_camxuc', '')

        if text_input:
            # Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
            processed_text = preprocess_text(text_input)

            # Vector h√≥a vƒÉn b·∫£n
            text_tfidf = tfidf.transform([processed_text])

            # D·ª± ƒëo√°n c·∫£m x√∫c
            predicted_sentiment = model.predict(text_tfidf)
            NoiDung = text_input

            result = 'T√≠ch c·ª±c üòä' if predicted_sentiment[0] == 'Tich cuc' else 'Ti√™u c·ª±c üòû'

    # Render k·∫øt qu·∫£
    return render(request, 'app/test_text.html', {'result': result, 'NoiDung': NoiDung})


def save_sentiment(request):
    """L∆∞u l·∫°i vƒÉn b·∫£n t√≠ch c·ª±c v√†o m√¥ h√¨nh."""
    if request.method == 'POST':
        text_input = request.POST.get('text')
        if text_input:
            # Ti·ªÅn x·ª≠ l√Ω v√† l∆∞u
            processed_text = preprocess_text(text_input)
            with open('./code_hkmay/liked_texts.txt', 'a') as f:
                f.write(f"{processed_text}\n")
        print("Redirecting to /text")
        return redirect('text')  # Chuy·ªÉn h∆∞·ªõng v·ªÅ trang text

def discard_sentiment(request):
    """B·ªè qua vƒÉn b·∫£n ti√™u c·ª±c, kh√¥ng l∆∞u l·∫°i."""
    if request.method == 'POST':
        print("Redirecting to /text")
        return redirect('text')  # Chuy·ªÉn h∆∞·ªõng v·ªÅ trang text
